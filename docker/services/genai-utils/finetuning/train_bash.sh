CUDA_VISIBLE_DEVICES=0 python3 app/src/train_bash.py --stage sft --model_name_or_path mistralai/Mistral-7B-v0.1 --use_fast_tokenizer True --do_train --dataset_dir ./LLaMA-Effcient-Tuning/data_for_fintune --dataset custom_data --template default --finetuning_type lora --lora_rank 8 --lora_target q_proj,k_proj,v_proj,o_proj --output_dir /data/repo --overwrite_output_dir True --overwrite_cache True --val_size 0.2 --per_device_train_batch_size 16 --gradient_accumulation_steps 4 --lr_scheduler_type cosine --logging_steps 10 --save_steps 100 --learning_rate 5e-05 --num_train_epochs 2.0 --plot_loss --bf16 --save_safetensors=True